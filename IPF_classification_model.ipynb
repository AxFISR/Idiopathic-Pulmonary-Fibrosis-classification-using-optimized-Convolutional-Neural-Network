{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# üì¶ Imports for Data Handling & Model\n",
        "# =============================\n",
        "\n",
        "# üîó Google Drive access\n",
        "from google.colab import drive\n",
        "\n",
        "# üìÅ File and image handling\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# üìä Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# üìà Evaluation metrics\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    accuracy_score\n",
        ")\n",
        "\n",
        "# ü§ñ TensorFlow and Keras (Deep Learning)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "metadata": {
        "id": "_lBCv76hdD0K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PoXT3nMcpxx",
        "outputId": "385c34c3-9253-49cd-d229-5190e40279d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "üìÅ Train Set: 3073 images\n",
            "  - IPF Positive: 1631 images (53.08%)\n",
            "  - IPF Negative: 1442 images (46.92%)\n",
            "\n",
            "üìÅ Test Set: 220 images\n",
            "  - IPF Positive: 103 images (46.82%)\n",
            "  - IPF Negative: 117 images (53.18%)\n",
            "\n",
            "üìÅ Validation Set: 1098 images\n",
            "  - IPF Positive: 535 images (48.72%)\n",
            "  - IPF Negative: 563 images (51.28%)\n",
            "\n",
            "üìä Grand Total: 4391 images\n",
            "  - Training   : 69.98%\n",
            "  - Testing    : 5.01%\n",
            "  - Validation : 25.01%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# =============================\n",
        "# üîó Mount Google Drive\n",
        "# =============================\n",
        "# Required for accessing dataset folders stored on Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# =============================\n",
        "# üìÅ Define Dataset Paths\n",
        "# =============================\n",
        "# Set the paths to the train, test, and validation image folders\n",
        "test_folder_path = \"/content/drive/MyDrive/Dataset/Test\"\n",
        "train_folder_path = \"/content/drive/MyDrive/Dataset/Train\"\n",
        "validation_folder_path = \"/content/drive/MyDrive/Dataset/Validation\"\n",
        "\n",
        "# =============================\n",
        "# üì• Function to Count Images per Class\n",
        "# =============================\n",
        "def count_images_in_folder(folder_path):\n",
        "    \"\"\"\n",
        "    Counts the number of images per label in a dataset folder.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): Path to the dataset folder.\n",
        "\n",
        "    Returns:\n",
        "        dict: Number of images for each label (\"IPF Positive\", \"IPF Negative\").\n",
        "        int: Total number of images in the folder.\n",
        "    \"\"\"\n",
        "    counts = {}\n",
        "    total = 0\n",
        "    for label in [\"IPF Positive\", \"IPF Negative\"]:\n",
        "        label_folder = os.path.join(folder_path, label)\n",
        "        if os.path.exists(label_folder):\n",
        "            num_images = len([\n",
        "                f for f in os.listdir(label_folder)\n",
        "                if f.endswith(('.png', '.jpg', '.jpeg'))\n",
        "            ])\n",
        "            counts[label] = num_images\n",
        "            total += num_images\n",
        "        else:\n",
        "            # If folder does not exist, count is zero\n",
        "            counts[label] = 0\n",
        "    return counts, total\n",
        "\n",
        "# =============================\n",
        "# üìä Count Images in Each Set\n",
        "# =============================\n",
        "train_counts, train_total = count_images_in_folder(train_folder_path)\n",
        "test_counts, test_total = count_images_in_folder(test_folder_path)\n",
        "val_counts, val_total = count_images_in_folder(validation_folder_path)\n",
        "\n",
        "# Calculate total number of images across all datasets\n",
        "grand_total = train_total + test_total + val_total\n",
        "\n",
        "# =============================\n",
        "# üñ®Ô∏è Print Dataset Summary\n",
        "# =============================\n",
        "print(f\"üìÅ Train Set: {train_total} images\")\n",
        "for label, count in train_counts.items():\n",
        "    print(f\"  - {label}: {count} images ({(count/train_total)*100:.2f}%)\")\n",
        "\n",
        "print(f\"\\nüìÅ Test Set: {test_total} images\")\n",
        "for label, count in test_counts.items():\n",
        "    print(f\"  - {label}: {count} images ({(count/test_total)*100:.2f}%)\")\n",
        "\n",
        "print(f\"\\nüìÅ Validation Set: {val_total} images\")\n",
        "for label, count in val_counts.items():\n",
        "    print(f\"  - {label}: {count} images ({(count/val_total)*100:.2f}%)\")\n",
        "\n",
        "print(f\"\\nüìä Grand Total: {grand_total} images\")\n",
        "print(f\"  - Training   : {(train_total / grand_total) * 100:.2f}%\")\n",
        "print(f\"  - Testing    : {(test_total / grand_total) * 100:.2f}%\")\n",
        "print(f\"  - Validation : {(val_total / grand_total) * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# üîó Mount Google Drive and Define Dataset Paths\n",
        "# =============================\n",
        "\n",
        "# Mount Google Drive (force_remount ensures re-connection if already mounted)\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "# Define folder paths for dataset splits\n",
        "train_folder_path = \"/content/drive/MyDrive/Dataset/Train\"\n",
        "validation_folder_path = \"/content/drive/MyDrive/Dataset/Validation\"\n",
        "test_folder_path = \"/content/drive/MyDrive/Dataset/Test\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGiJHOcxdga-",
        "outputId": "617ad5ae-156c-469f-9bd4-929d5d8c9389"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# üì• Image Loading Function\n",
        "# =============================\n",
        "def load_data(image_folder_path, image_size, data, label):\n",
        "    \"\"\"\n",
        "    Loads grayscale images from a specified folder, resizes them,\n",
        "    and appends them with their label to a given list.\n",
        "\n",
        "    Args:\n",
        "        image_folder_path (str): Path to the image folder.\n",
        "        image_size (int): Target width and height (images will be resized to image_size x image_size).\n",
        "        data (list): List to which (image, label) pairs will be appended.\n",
        "        label (int): Integer label to assign to all images in this folder.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(image_folder_path):\n",
        "        print(f\"‚ùå Error: Folder not found at {image_folder_path}\")\n",
        "        return\n",
        "\n",
        "    for imagename in os.listdir(image_folder_path):\n",
        "        if imagename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            try:\n",
        "                # Construct full image path\n",
        "                image_path = os.path.join(image_folder_path, imagename)\n",
        "\n",
        "                # Load the image in grayscale\n",
        "                image_array = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                # Resize to the desired dimensions\n",
        "                image_array = cv2.resize(image_array, (image_size, image_size))\n",
        "\n",
        "                # Append image and label if image is valid\n",
        "                if image_array is not None and image_array.size > 0:\n",
        "                    data.append([image_array, label])\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error opening image '{imagename}': {e}\")\n"
      ],
      "metadata": {
        "id": "M4u7ZagHdolq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# üè∑Ô∏è Dataset Preparation\n",
        "# =============================\n",
        "\n",
        "# Image dimensions for resizing (grayscale: 256x256, can be changed according to the dataset)\n",
        "IMAGE_SIZE = 256\n",
        "\n",
        "# Class labels used for folder names and labeling\n",
        "labels = [\"IPF Positive\", \"IPF Negative\"]\n",
        "\n",
        "def build_data(path, labels=labels):\n",
        "    \"\"\"\n",
        "    Loads and labels image data from a given directory path.\n",
        "\n",
        "    Args:\n",
        "        path (str): Base folder containing class subfolders.\n",
        "        labels (list): List of label names corresponding to folder names.\n",
        "\n",
        "    Returns:\n",
        "        list: Shuffled list of (image, label) pairs.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "\n",
        "    # Load IPF Positive images with label 0\n",
        "    load_data(os.path.join(path, \"IPF Positive\"), IMAGE_SIZE, data, labels.index(\"IPF Positive\"))\n",
        "\n",
        "    # Load IPF Negative images with label 1\n",
        "    load_data(os.path.join(path, \"IPF Negative\"), IMAGE_SIZE, data, labels.index(\"IPF Negative\"))\n",
        "\n",
        "    # Shuffle to randomize order\n",
        "    random.shuffle(data)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Prepare training, validation, and test datasets\n",
        "train_data = build_data(train_folder_path)\n",
        "validation_data = build_data(validation_folder_path)\n",
        "test_data = build_data(test_folder_path)\n"
      ],
      "metadata": {
        "id": "mSA-EYHQd3eN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# üîÑ Convert Data to Numpy Arrays\n",
        "# =============================\n",
        "\n",
        "def convert_to_np_array(data):\n",
        "    \"\"\"\n",
        "    Splits a list of (image, label) pairs into separate NumPy arrays.\n",
        "\n",
        "    Args:\n",
        "        data (list): List of (image_array, label) pairs.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, np.ndarray]: Arrays for X (images) and Y (labels).\n",
        "    \"\"\"\n",
        "    x, y = [], []\n",
        "    for image, label in data:\n",
        "        x.append(image)\n",
        "        y.append(label)\n",
        "    X = np.array(x, dtype=float)\n",
        "    Y = np.array(y, dtype=float)\n",
        "    return X, Y\n",
        "\n",
        "# Convert training, validation, and test data into X (image) and Y (label) arrays\n",
        "train_data_x, train_data_y = convert_to_np_array(train_data)\n",
        "validation_data_x, validation_data_y = convert_to_np_array(validation_data)\n",
        "test_data_x, test_data_y = convert_to_np_array(test_data)\n",
        "\n",
        "# Add channel dimension for grayscale (shape becomes: [batch, 256, 256, 1])\n",
        "train_data_x = np.expand_dims(train_data_x, axis=-1)\n",
        "validation_data_x = np.expand_dims(validation_data_x, axis=-1)\n",
        "test_data_x = np.expand_dims(test_data_x, axis=-1)\n",
        "\n",
        "# Normalize pixel values to range [0, 1]\n",
        "# Note: Dividing by 255.0 is standard for 8-bit grayscale images (values originally 0‚Äì255)\n",
        "train_data_x = train_data_x / 255.0\n",
        "validation_data_x = validation_data_x / 255.0\n",
        "test_data_x = test_data_x / 255.0\n"
      ],
      "metadata": {
        "id": "SBqAujhPeG5w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# üß† Model Hyperparameters\n",
        "# =============================\n",
        "\n",
        "BATCH_SIZE = 64         # Number of training samples per batch\n",
        "EPOCHS = 150            # Total number of passes through the entire training set\n",
        "LEARNING_RATE = 5e-6    # Learning rate for the optimizer (small for fine-tuning)\n",
        "DROPOUT_RATE = 0.45      # Fraction of neurons to drop during training (prevents overfitting)\n"
      ],
      "metadata": {
        "id": "xuOgLTCleRkp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# üèóÔ∏è Build CNN Model\n",
        "# =============================\n",
        "\n",
        "# Simple custom CNN for binary image classification (grayscale 256x256 inputs)\n",
        "model = Sequential([\n",
        "    # Convolutional Block 1\n",
        "    Conv2D(16, (3, 3), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Convolutional Block 2\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Convolutional Block 3\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Convolutional Block 4\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Fully Connected Head\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(DROPOUT_RATE),\n",
        "\n",
        "    # Output Layer: 2 neurons (IPF Positive, IPF Negative)\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model with Adam optimizer and sparse categorical loss\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "    loss='sparse_categorical_crossentropy',  # Use sparse targets (integers 0 and 1)\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fdwTCJrebh0",
        "outputId": "dd792bee-1f14-45a5-d76b-2cba811e94ff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# üîÑ Create TensorFlow Dataset Pipeline (with Optional Augmentation)\n",
        "# =============================\n",
        "\n",
        "# Toggle to enable or disable data augmentation for the training set\n",
        "AUGMENTATION_ENABLED = True\n",
        "\n",
        "def augment_image(x, y):\n",
        "    \"\"\"\n",
        "    Applies random augmentations to an image tensor.\n",
        "    Used to improve model generalization and reduce overfitting.\n",
        "\n",
        "    Augmentations:\n",
        "    - Random horizontal flip\n",
        "    - Random vertical flip\n",
        "    - Brightness jitter\n",
        "    - Contrast jitter\n",
        "    \"\"\"\n",
        "    x = tf.image.random_flip_left_right(x)\n",
        "    x = tf.image.random_flip_up_down(x)\n",
        "    x = tf.image.random_brightness(x, max_delta=0.1)\n",
        "    x = tf.image.random_contrast(x, lower=0.9, upper=1.1)\n",
        "    return tf.cast(x, tf.float32), tf.cast(y, tf.int32)\n",
        "\n",
        "def basic_cast(x, y):\n",
        "    \"\"\"\n",
        "    Converts image and label to TensorFlow float32/int32 without augmentation.\n",
        "    \"\"\"\n",
        "    return tf.cast(x, tf.float32), tf.cast(y, tf.int32)\n",
        "\n",
        "# Create the training dataset pipeline\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_data_x, train_data_y))\n",
        "train_dataset = train_dataset.map(augment_image if AUGMENTATION_ENABLED else basic_cast)\n",
        "train_dataset = train_dataset.shuffle(1000)        # Shuffle training data\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)    # Batch it\n",
        "train_dataset = train_dataset.repeat()             # Repeat indefinitely for multiple epochs\n",
        "\n",
        "# Validation and test sets use no augmentation\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((validation_data_x, validation_data_y))\n",
        "val_dataset = val_dataset.map(basic_cast).batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_data_x, test_data_y))\n",
        "test_dataset = test_dataset.map(basic_cast).batch(BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "Sn73b2QTej60"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# üöÇ Train the Model\n",
        "# =============================\n",
        "\n",
        "# Determine how many batches per epoch based on training data size\n",
        "steps_per_epoch = len(train_data_x) // BATCH_SIZE\n",
        "\n",
        "# Fit the model using the prepared dataset pipelines\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_dataset\n",
        ")\n",
        "\n",
        "# =============================\n",
        "# üíæ Save the Trained Model\n",
        "# =============================\n",
        "MODEL_PATH = \"/content/drive/MyDrive/saved_model.h5\"\n",
        "model.save(MODEL_PATH)\n",
        "print(f\"‚úÖ Model saved to: {MODEL_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeKWW5Jqeo7x",
        "outputId": "0b9176a2-ffc6-4ab7-feb4-048e54e94ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 6s/step - accuracy: 0.5319 - loss: 0.6870 - val_accuracy: 0.4872 - val_loss: 0.6951\n",
            "Epoch 2/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 6s/step - accuracy: 0.5172 - loss: 0.6836 - val_accuracy: 0.4909 - val_loss: 0.6891\n",
            "Epoch 3/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 5s/step - accuracy: 0.5564 - loss: 0.6660 - val_accuracy: 0.5392 - val_loss: 0.6761\n",
            "Epoch 4/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 5s/step - accuracy: 0.6206 - loss: 0.6573 - val_accuracy: 0.5956 - val_loss: 0.6668\n",
            "Epoch 5/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 5s/step - accuracy: 0.7131 - loss: 0.6441 - val_accuracy: 0.6767 - val_loss: 0.6513\n",
            "Epoch 6/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 5s/step - accuracy: 0.7488 - loss: 0.6273 - val_accuracy: 0.7158 - val_loss: 0.6340\n",
            "Epoch 7/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 5s/step - accuracy: 0.7691 - loss: 0.6002 - val_accuracy: 0.7796 - val_loss: 0.6090\n",
            "Epoch 8/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 5s/step - accuracy: 0.7923 - loss: 0.5845 - val_accuracy: 0.7687 - val_loss: 0.5995\n",
            "Epoch 9/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 5s/step - accuracy: 0.7996 - loss: 0.5569 - val_accuracy: 0.7978 - val_loss: 0.5774\n",
            "Epoch 10/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 5s/step - accuracy: 0.8067 - loss: 0.5337 - val_accuracy: 0.8106 - val_loss: 0.5579\n",
            "Epoch 11/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 5s/step - accuracy: 0.8193 - loss: 0.5194 - val_accuracy: 0.8188 - val_loss: 0.5440\n",
            "Epoch 12/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 5s/step - accuracy: 0.8224 - loss: 0.5118 - val_accuracy: 0.8242 - val_loss: 0.5327\n",
            "Epoch 13/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 5s/step - accuracy: 0.8322 - loss: 0.4782 - val_accuracy: 0.8251 - val_loss: 0.5277\n",
            "Epoch 14/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 5s/step - accuracy: 0.8430 - loss: 0.4616 - val_accuracy: 0.8288 - val_loss: 0.5087\n",
            "Epoch 15/100\n",
            "\u001b[1m 9/48\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m2:52\u001b[0m 4s/step - accuracy: 0.8418 - loss: 0.4413"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# üßæ Evaluate Model (Train/Validation/Test Results)\n",
        "# =============================\n",
        "\n",
        "# 1Ô∏è‚É£ Get Best Training and Validation Accuracies from Training History\n",
        "best_train_acc = max(history.history['accuracy'])\n",
        "best_val_acc = max(history.history['val_accuracy'])\n",
        "\n",
        "# 2Ô∏è‚É£ Evaluate the model on the test dataset\n",
        "# Returns final test loss and accuracy\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset, verbose=1)\n",
        "\n",
        "# 3Ô∏è‚É£ Print Summary of Results\n",
        "print(\"\\nüèÅ Final Results:\")\n",
        "print(f\"üìà Best Train Accuracy      : {best_train_acc:.4f}\")\n",
        "print(f\"üìà Best Validation Accuracy : {best_val_acc:.4f}\")\n",
        "print(f\"üìà Final Test Accuracy      : {test_accuracy:.4f}\")\n",
        "print(f\"üìâ Final Test Loss          : {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "ZHY458zlewS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# üìà Accuracy & Loss Curves (Improved)\n",
        "# =============================\n",
        "\n",
        "# üìä Accuracy Plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()\n",
        "\n",
        "# üìâ Loss Plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()\n",
        "\n",
        "# =============================\n",
        "# üìä Performance Metrics (Confusion Matrix & Scores)\n",
        "# =============================\n",
        "\n",
        "# üîç Predict class probabilities for test data\n",
        "result = model.predict(test_data_x)\n",
        "\n",
        "# üéØ Convert predicted probabilities to class labels\n",
        "predicted_labels = np.argmax(result, axis=1)\n",
        "\n",
        "# üìâ Confusion Matrix\n",
        "cm = confusion_matrix(test_data_y, predicted_labels)\n",
        "class_labels = ['IPF Positive', 'IPF Negative']\n",
        "\n",
        "# üîµ Confusion Matrix Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_labels,\n",
        "            yticklabels=class_labels)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# üßÆ Classification Metrics\n",
        "precision = precision_score(test_data_y, predicted_labels)\n",
        "recall = recall_score(test_data_y, predicted_labels)\n",
        "f1 = f1_score(test_data_y, predicted_labels)\n",
        "accuracy = accuracy_score(test_data_y, predicted_labels)\n",
        "\n",
        "# üñ®Ô∏è Print Final Evaluation Metrics\n",
        "print(f\"Accuracy : {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall   : {recall:.4f}\")\n",
        "print(f\"F1 Score : {f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "mcB3GLXRe1OQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# üß∞ Setup and Environment Configuration\n",
        "# =============================\n",
        "\n",
        "!pip install ipywidgets --quiet\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow warnings\n",
        "import logging\n",
        "logging.getLogger('tensorflow').setLevel(logging.FATAL)\n",
        "\n",
        "# General Imports\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import io\n",
        "import base64\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# GUI and Display\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Deep Learning\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Google Drive Access\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "# =============================\n",
        "# üß† Load Pretrained Model\n",
        "# =============================\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/saved_model.h5\"\n",
        "IMAGE_SIZE = 256\n",
        "model = load_model(MODEL_PATH, compile=False)\n",
        "\n",
        "# =============================\n",
        "# üñºÔ∏è GUI Widgets Setup\n",
        "# =============================\n",
        "\n",
        "# Folder input widget\n",
        "folder_input = widgets.Text(\n",
        "    value=\"/content/drive/MyDrive/Patient_Folder\",\n",
        "    placeholder=\"Paste patient folder path here\",\n",
        "    description=\"üìÅ Folder:\",\n",
        "    layout=widgets.Layout(width='95%')\n",
        ")\n",
        "\n",
        "# Diagnose button\n",
        "diagnose_button = widgets.Button(\n",
        "    description=\"ü©∫ Diagnose\",\n",
        "    button_style=\"success\",\n",
        "    icon=\"search\",\n",
        "    layout=widgets.Layout(width='30%')\n",
        ")\n",
        "\n",
        "# Loader, progress, and output display areas\n",
        "loader = widgets.Label(value=\"\")\n",
        "progress_bar = widgets.IntProgress(value=0, min=0, max=100, description='Progress:',\n",
        "                                   bar_style='info', style={'description_width': 'initial'},\n",
        "                                   layout=widgets.Layout(width='80%'))\n",
        "output = widgets.Output()\n",
        "image_display_box = widgets.HTML(value=\"\")\n",
        "\n",
        "# =============================\n",
        "# üì¶ Image Utility Functions\n",
        "# =============================\n",
        "\n",
        "# Convert NumPy image to base64 for HTML embedding\n",
        "def img_to_b64(img_np):\n",
        "    img = Image.fromarray(img_np)\n",
        "    buffer = io.BytesIO()\n",
        "    img.save(buffer, format=\"PNG\")\n",
        "    return base64.b64encode(buffer.getvalue()).decode()\n",
        "\n",
        "# Create a styled HTML block for each image prediction\n",
        "def render_image_html(img_b64, title, is_flagged=False):\n",
        "    border = \"3px solid red\" if is_flagged else \"1px solid #ccc\"\n",
        "    return f\"\"\"\n",
        "        <div style=\"margin:5px;text-align:center;border:{border};padding:4px;width:150px;\">\n",
        "            <img src=\"data:image/png;base64,{img_b64}\" style=\"width:100%;border-radius:6px;\">\n",
        "            <div style=\"font-size:11px; font-weight:bold; margin-top:3px;\">{title}</div>\n",
        "        </div>\n",
        "    \"\"\"\n",
        "\n",
        "# =============================\n",
        "# üß™ Evaluate Patient Folder in Real-Time\n",
        "# =============================\n",
        "\n",
        "def evaluate_patient_live(folder_path):\n",
        "    filenames, predictions, predicted_labels, images = [], [], [], []\n",
        "    grid_html = \"<div style='display:flex;flex-wrap:wrap;justify-content:center;'>\"\n",
        "\n",
        "    files = sorted([f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "    total = len(files)\n",
        "    progress_bar.max = total\n",
        "\n",
        "    for idx, filename in enumerate(files):\n",
        "        path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        img_rgb = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
        "        image_resized = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "        image_input = image_resized.reshape(1, IMAGE_SIZE, IMAGE_SIZE, 1) / 255.0\n",
        "\n",
        "        pred = model.predict(image_input, verbose=0)[0]\n",
        "        predictions.append(pred)\n",
        "        predicted_labels.append(np.argmax(pred))\n",
        "        filenames.append(filename)\n",
        "        images.append(img_rgb)\n",
        "\n",
        "        label = \"IPF Positive\" if np.argmax(pred) == 0 else \"IPF Negative\"\n",
        "        pred_str = f\"{pred[0]:.2f}/{pred[1]:.2f}\"\n",
        "        b64img = img_to_b64(cv2.resize(img_rgb, (150, 150)))\n",
        "        grid_html += render_image_html(b64img, f\"{filename}<br>{label}<br>({pred_str})\")\n",
        "\n",
        "        progress_bar.value = idx + 1\n",
        "        progress_bar.description = f\"Diagnosed {idx + 1}/{total}\"\n",
        "        image_display_box.value = grid_html + \"</div>\"\n",
        "\n",
        "        time.sleep(0.15)  # Simulated delay for real-time effect\n",
        "\n",
        "    return filenames, predictions, predicted_labels, images\n",
        "\n",
        "# =============================\n",
        "# üñ±Ô∏è On Diagnose Button Click\n",
        "# =============================\n",
        "\n",
        "def on_diagnose_clicked(b):\n",
        "    with output:\n",
        "        clear_output()\n",
        "        loader.value = \"üîÑ Diagnosing, please wait...\"\n",
        "        folder_path = folder_input.value.strip()\n",
        "\n",
        "        if not os.path.exists(folder_path):\n",
        "            loader.value = \"‚ùå Folder does not exist!\"\n",
        "            return\n",
        "\n",
        "        image_display_box.value = \"\"\n",
        "        filenames, predictions, predicted_labels, images = evaluate_patient_live(folder_path)\n",
        "\n",
        "        total = len(predicted_labels)\n",
        "        positive = predicted_labels.count(0)\n",
        "        negative = predicted_labels.count(1)\n",
        "        final_vote = 0 if positive > negative else 1\n",
        "        final_diagnosis = \"IPF Positive\" if final_vote == 0 else \"IPF Negative\"\n",
        "        loader.value = \"\"\n",
        "\n",
        "        # === Final Summary Display\n",
        "        summary_html = widgets.HTML(\n",
        "            value=f\"\"\"\n",
        "            <div style=\"background: #f9f9f9; border: 2px solid #007bff;\n",
        "                        padding: 20px 30px; border-radius: 12px;\n",
        "                        width: 60%; margin: auto;\n",
        "                        box-shadow: 0 4px 12px rgba(0,0,0,0.15);\n",
        "                        font-family: Arial, sans-serif; color: #111;\">\n",
        "                <h2 style=\"text-align:center; color:#007bff; margin-top:0;\">ü©∫ Final Patient Diagnosis</h2>\n",
        "                <p style=\"font-size:16px;\"><strong>Total Images:</strong> {total}</p>\n",
        "                <p style=\"font-size:16px;\"><strong>IPF Positive:</strong> {positive} ({(positive/total)*100:.2f}%)</p>\n",
        "                <p style=\"font-size:16px;\"><strong>IPF Negative:</strong> {negative} ({(negative/total)*100:.2f}%)</p>\n",
        "                <p style=\"font-size:18px; margin-top:20px;\">\n",
        "                    <strong>üß† Final Diagnosis:</strong>\n",
        "                    <span style=\"color:{'red' if final_diagnosis == 'IPF Positive' else 'green'}; font-weight:bold;\">\n",
        "                        {final_diagnosis}\n",
        "                    </span>\n",
        "                </p>\n",
        "            </div>\n",
        "            \"\"\")\n",
        "        display(summary_html)\n",
        "\n",
        "        # === Flagged Image Display (disagrees with final diagnosis)\n",
        "        flagged_html = \"<div style='margin-top:30px;text-align:center;'><h3>üü• Flagged Predictions (Opposite to Final Diagnosis)</h3></div>\"\n",
        "        flagged_html += \"<div style='display:flex;flex-wrap:wrap;justify-content:center;'>\"\n",
        "\n",
        "        found_flagged = False\n",
        "        for i, pred in enumerate(predictions):\n",
        "            individual_vote = np.argmax(pred)\n",
        "            if individual_vote != final_vote:\n",
        "                found_flagged = True\n",
        "                label = \"IPF Positive\" if individual_vote == 0 else \"IPF Negative\"\n",
        "                pred_str = f\"{pred[0]:.2f}/{pred[1]:.2f}\"\n",
        "                b64img = img_to_b64(cv2.resize(images[i], (150, 150)))\n",
        "                flagged_html += render_image_html(b64img, f\"{filenames[i]}<br>{label}<br>({pred_str})\", is_flagged=True)\n",
        "\n",
        "        flagged_html += \"</div>\"\n",
        "        if found_flagged:\n",
        "            display(HTML(flagged_html))\n",
        "        else:\n",
        "            display(HTML(\"<p style='text-align:center;color:#555;'>‚úÖ No flagged predictions found.</p>\"))\n",
        "\n",
        "# =============================\n",
        "# üí° Launch the GUI\n",
        "# =============================\n",
        "\n",
        "diagnose_button.on_click(on_diagnose_clicked)\n",
        "display(folder_input, diagnose_button, loader, progress_bar, image_display_box, output)\n"
      ],
      "metadata": {
        "id": "3BGaah8PfOoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# üîÅ Transfer Learning: Fine-Tune a Saved Model with New Data (With Frozen Layers)\n",
        "# =============================\n",
        "\n",
        "# === Imports\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "from google.colab import drive\n",
        "\n",
        "# üîó Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# =============================\n",
        "# üìÅ Define Paths and Constants\n",
        "# =============================\n",
        "MODEL_PATH = \"/content/drive/MyDrive/saved_model.h5\"\n",
        "FINE_TUNED_MODEL_PATH = \"/content/drive/MyDrive/saved_model_finetuned.h5\"\n",
        "NEW_DATA_PATH = \"/content/drive/MyDrive/transfer learning\"\n",
        "VALIDATION_PATH = \"/content/drive/MyDrive/transfer test/Validation\"\n",
        "\n",
        "IMAGE_SIZE = 256\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 5e-6\n",
        "AUGMENTATION_ENABLED = True\n",
        "LABELS = [\"IPF Positive\", \"IPF Negative\"]\n",
        "\n",
        "# =============================\n",
        "# üß† Load and Recompile the Model\n",
        "# =============================\n",
        "model = load_model(MODEL_PATH, compile=False)\n",
        "\n",
        "# Optionally freeze layers before fine-tuning\n",
        "# for layer in model.layers[:-2]:\n",
        "#     layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# =============================\n",
        "# üñºÔ∏è Data Loading Functions\n",
        "# =============================\n",
        "def load_images_from_folder(path, label):\n",
        "    \"\"\"\n",
        "    Loads grayscale images from a subfolder named after the label.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    folder = os.path.join(path, label)\n",
        "    for fname in os.listdir(folder):\n",
        "        if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            try:\n",
        "                img_path = os.path.join(folder, fname)\n",
        "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "                data.append((img, LABELS.index(label)))\n",
        "            except:\n",
        "                pass\n",
        "    return data\n",
        "\n",
        "def prepare_data(folder_path):\n",
        "    \"\"\"\n",
        "    Prepares dataset as normalized tensors from a labeled folder path.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for label in LABELS:\n",
        "        data.extend(load_images_from_folder(folder_path, label))\n",
        "    random.shuffle(data)\n",
        "    x, y = zip(*data)\n",
        "    x = np.array(x).reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 1) / 255.0  # Normalize to [0,1]\n",
        "    y = np.array(y)\n",
        "    return x, y\n",
        "\n",
        "# =============================\n",
        "# üß™ Prepare Training and Validation Data\n",
        "# =============================\n",
        "train_x, train_y = prepare_data(NEW_DATA_PATH)\n",
        "val_x, val_y = prepare_data(VALIDATION_PATH)\n",
        "\n",
        "# =============================\n",
        "# üîÑ Data Augmentation Functions\n",
        "# =============================\n",
        "def augment_image(x, y):\n",
        "    x = tf.image.random_flip_left_right(x)\n",
        "    x = tf.image.random_flip_up_down(x)\n",
        "    x = tf.image.random_brightness(x, max_delta=0.1)\n",
        "    x = tf.image.random_contrast(x, lower=0.9, upper=1.1)\n",
        "    return tf.cast(x, tf.float32), tf.cast(y, tf.int32)\n",
        "\n",
        "def basic_cast(x, y):\n",
        "    return tf.cast(x, tf.float32), tf.cast(y, tf.int32)\n",
        "\n",
        "# =============================\n",
        "# üì¶ TensorFlow Dataset Pipeline\n",
        "# =============================\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "train_dataset = train_dataset.map(augment_image if AUGMENTATION_ENABLED else basic_cast)\n",
        "train_dataset = train_dataset.shuffle(1000).batch(BATCH_SIZE).repeat()\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
        "val_dataset = val_dataset.map(basic_cast).batch(BATCH_SIZE)\n",
        "\n",
        "# =============================\n",
        "# üöÇ Fine-Tune the Model\n",
        "# =============================\n",
        "steps = len(train_x) // BATCH_SIZE\n",
        "\n",
        "fine_tune_history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=60,\n",
        "    steps_per_epoch=steps,\n",
        "    validation_data=val_dataset\n",
        ")\n",
        "\n",
        "# =============================\n",
        "# üíæ Save the Fine-Tuned Model\n",
        "# =============================\n",
        "model.save(FINE_TUNED_MODEL_PATH)\n",
        "print(f\"‚úÖ Fine-tuned model saved at: {FINE_TUNED_MODEL_PATH}\")\n"
      ],
      "metadata": {
        "id": "YuzOjjBMgBic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# üìä Transfer Learning Evaluation on Test Set\n",
        "# =============================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    accuracy_score\n",
        ")\n",
        "\n",
        "# =============================\n",
        "# üß™ Load and Prepare Test Set\n",
        "# =============================\n",
        "TEST_PATH = \"/content/drive/MyDrive/transfer test/Test\"\n",
        "test_x, test_y = prepare_data(TEST_PATH)  # Uses same preprocessing as training/validation\n",
        "\n",
        "test_x_array = np.array(test_x)\n",
        "test_y_array = np.array(test_y)\n",
        "\n",
        "# =============================\n",
        "# üîÆ Generate Predictions\n",
        "# =============================\n",
        "predictions = model.predict(test_x_array)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# =============================\n",
        "# üìâ Confusion Matrix\n",
        "# =============================\n",
        "cm = confusion_matrix(test_y_array, predicted_labels)\n",
        "class_labels = ['IPF Positive', 'IPF Negative']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_labels,\n",
        "            yticklabels=class_labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix (Test Set)')\n",
        "plt.show()\n",
        "\n",
        "# =============================\n",
        "# üßæ Final Classification Metrics\n",
        "# =============================\n",
        "accuracy = accuracy_score(test_y_array, predicted_labels)\n",
        "precision = precision_score(test_y_array, predicted_labels)\n",
        "recall = recall_score(test_y_array, predicted_labels)\n",
        "f1 = f1_score(test_y_array, predicted_labels)\n",
        "\n",
        "print(\"\\nüèÅ Fine-Tuned Results:\")\n",
        "print(f\"üìà Accuracy : {accuracy:.4f}\")\n",
        "print(f\"üìà Precision: {precision:.4f}\")\n",
        "print(f\"üìà Recall   : {recall:.4f}\")\n",
        "print(f\"üìà F1 Score : {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "lyiDx66SgNvD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
